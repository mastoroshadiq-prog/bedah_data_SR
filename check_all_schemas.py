"""
COMPREHENSIVE CHECK - All CSV vs SQL Schema Mismatches
Check all remaining tables (3-8) at once
"""

import pandas as pd
import os

print("=" * 100)
print("COMPREHENSIVE SCHEMA CHECK - ALL TABLES")
print("=" * 100)

# Define all tables and their CSV files
tables = [
    {
        'num': 1,
        'name': 'estates',
        'file': 'output/normalized_tables/phase1_core/estates.csv',
        'status': '✅ Already uploaded'
    },
    {
        'num': 2,
        'name': 'blocks',
        'file': 'output/normalized_tables/phase1_core/blocks_standardized.csv',
        'status': '✅ Already uploaded'
    },
    {
        'num': 3,
        'name': 'block_land_infrastructure',
        'file': 'output/normalized_tables/phase2_metadata/block_land_infrastructure.csv',
        'status': '⏳ Pending'
    },
    {
        'num': 4,
        'name': 'block_pest_disease',
        'file': 'output/normalized_tables/phase2_metadata/block_pest_disease.csv',
        'status': '⏳ Pending'
    },
    {
        'num': 5,
        'name': 'block_planting_history',
        'file': 'output/normalized_tables/phase2_metadata/block_planting_history.csv',
        'status': '⏳ Pending'
    },
    {
        'num': 6,
        'name': 'block_planting_yearly',
        'file': 'output/normalized_tables/phase2_metadata/block_planting_yearly.csv',
        'status': '⏳ Pending'
    },
    {
        'num': 7,
        'name': 'production_annual',
        'file': 'output/normalized_tables/phase3_production/production_annual.csv',
        'status': '⏳ Pending'
    },
    {
        'num': 8,
        'name': 'production_monthly',
        'file': 'output/normalized_tables/phase3_production/production_monthly.csv',
        'status': '⏳ Pending'
    }
]

# Check each table
results = []

for table in tables:
    num = table['num']
    name = table['name']
    file_path = table['file']
    status = table['status']
    
    print(f"\n[{num}/8] {name}")
    print(f"      Status: {status}")
    print(f"      File: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"      ❌ File not found!")
        results.append({
            'table': name,
            'status': 'FILE_NOT_FOUND',
            'columns': []
        })
        continue
    
    df = pd.read_csv(file_path)
    cols = df.columns.tolist()
    
    print(f"      Records: {len(df):,}")
    print(f"      Columns ({len(cols)}):")
    
    # Show all columns
    for i, col in enumerate(cols, 1):
        print(f"        {i:2d}. {col}")
    
    # Remove created_at if exists (auto-generated by DB)
    cols_cleaned = [c for c in cols if c != 'created_at']
    
    results.append({
        'table': name,
        'status': 'OK' if status == '✅ Already uploaded' else 'PENDING',
        'file': file_path,
        'records': len(df),
        'columns': cols,
        'columns_cleaned': cols_cleaned
    })

# Generate summary
print("\n" + "=" * 100)
print("SUMMARY - COLUMNS TO KEEP")
print("=" * 100)

for result in results:
    if result['status'] in ['OK', 'PENDING']:
        print(f"\n{result['table']}:")
        print(f"  Columns: {', '.join(result['columns_cleaned'])}")

# Save to file for SQL generation
with open('output/sql_schema/csv_schema_analysis.txt', 'w') as f:
    f.write("CSV SCHEMA ANALYSIS\n")
    f.write("=" * 100 + "\n\n")
    
    for result in results:
        if result['status'] in ['OK', 'PENDING']:
            f.write(f"{result['table']}:\n")
            f.write(f"  Records: {result['records']:,}\n")
            f.write(f"  Columns: {', '.join(result['columns_cleaned'])}\n\n")

print("\n" + "=" * 100)
print("✅ Analysis complete!")
print("=" * 100)
print(f"\nSaved to: output/sql_schema/csv_schema_analysis.txt")
print("\nNext: I'll generate SQL to fix all tables at once!")
